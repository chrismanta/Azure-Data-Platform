# DP-200-Implementing-an-Azure-Data-Solution

 During this course, the first and the last lab of the course are group exercises that involve discussion to help provide context for the labs that the students will take. The last lab provides the opportunity for the students to reflect on what they have achieved and what they have overcome to achieve the delivery of requirements from the case study in the labs. The rest of the labs are hands on implementing Azure data platform capabilities to meet AdventureWorks business requirements.

 [Case Study](course-case-study.md)

The following is a summary of the lab objectives for each module:

## [Lab 1 - Azure for the Data Engineer](Lab%2001%20-%20Azure%20for%20the%20Data%20Engineer\dp-200-01_instructions.md)

The students will take the information gained in the lessons and from the case study to scope out the deliverables for a digital transformation project within AdventureWorks. They will first identify how the evolving use of data has presented new opportunities for the organization. The students will also explore which Azure Data Platform services can be used to address the business needs and define the tasks that will be performed by the data engineer. Finally, students will finalize the data engineering deliverables for AdventureWorks.

## [Lab 2 - Working with Data Storage](Lab%2002%20-%20Working%20with%20Data%20Storage\dp-200-02_instructions.md)

In this lab, the students will be able to determine the appropriate storage type to implement against a given set of business and technical requirements. They will be able to create Azure storage accounts and Data Lake Storage account and explain the difference between Data Lake Storage version 1 and version 2. They will also be able to demonstrate how to perform data loads into the data storage of choice.

## [Lab 3 - Enabling Team Based Data Science with Azure Databricks](Lab%2003%20-%20Enabling%20Team%20Based%20Data%20Science%20with%20Azure%20Databricks\dp-200-03_instructions.md)

By the end of this lab the student will be able to explain why Azure Databricks can be used to help in Data Science projects. The students will provision and Azure Databricks instance and will then create a workspace that will be used to perform a simple data preparation task from a Data Lake Store Gen II store. Finally, the student will perform a walk-through of performing transformations using Azure Databricks.

## [Lab 4 - Building Globally Distributed Databases with Cosmos DB](Lab%2004%20-%20Building%20Globally%20Distributed%20Databases%20with%20Cosmos%20DB\dp-200-04_instructions.md)

The students will be able to describe and demonstrate the capabilities that Azure Cosmos DB can bring to an organization. They will be able to create a Cosmos DB instance and show how to upload and query data through a portal and through a .Net application. They will then be able to demonstrate how to enable global scale of the Cosmos DB database.

## [Lab 5 - Working with Relational Data Stores in the Cloud](Lab%2005%20-%20Working%20with%20Relational%20Data%20Stores%20in%20the%20Cloud\dp-200-05_instructions.md)

The students will be able to provision an Azure SQL Database and Azure Synapse Analytics to be able to issue queries against one of the instances that are created. They will be also be able to integrate Azure Synapse Analytics with a number of other Data platform technologies and use PolyBase to load data from one data source into a data warehouse.

## [Lab 6 - Performing Real-Time Analytics with Stream Analytics](Lab%2006%20-%20Performing%20Real-Time%20Analytics%20with%20Stream%20Analytics\dp-200-06_instructions.md)

The students will be able to describe what data streams are and how event processing works and choose an appropriate data stream ingestion technology for the AdventureWorks case study. They will provision the chosen ingestion technology and integrate this with Stream Analytics to create a solution that works with streaming data.

## [Lab 7 - Orchestrating Data Movement with Azure Data Factory](Lab%2007%20-%20Orchestrating%20Data%20Movement%20with%20Azure%20Data%20Factory\dp-200-07_instructions.md)

In this module, students will learn how Azure Data factory can be used to orchestrate the data movement from a wide range of data platform technologies. They will be able to explain the capabilities of the technology and be able to set up an end to end data pipeline that ingests data from SQL Database and load the data into SQL Data Warehouse. The student will also demonstrate how to call a compute resource.

## [Lab 8 - Securing Azure Data Platforms](Lab%2008%20-%20Securing%20Azure%20Data%20Platforms\dp-200-08_instructions.md)

The students will be able to describe and document the different approaches to security that can be taken to provide defence in depth. This will involve the student documenting the security that has been set up so far in the course. It will also enable the students to identify any gaps in security that may exists for AdventureWorks.

## [Lab 9 - Monitoring and Troubleshooting Data Storage and Processing](Lab%2009%20-%20Monitoring%20and%20Troubleshooting%20Data%20Storage%20and%20Processing\dp-200-09_instructions.md)

The students will be able to define a broad monitoring solution that can help them monitor issues that can occur in their data estate. The student will then experience common data storage issues and data processing issue that can occur in cloud data solution. Finally they will implement a disaster recovery approach for a Data Platform technology.